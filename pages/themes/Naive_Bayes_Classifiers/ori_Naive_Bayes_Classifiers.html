<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Naive_Bayes_Classifiers</title>
    <link rel="shortcut icon" href="/ML_SA-Slides/favicon.ico">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
    <!-- css & themes include -->
    <link rel="stylesheet" href="/ML_SA-Slides/lib/reveal.js/css/reveal.css">
    <link rel="stylesheet" href="/ML_SA-Slides/outfit/css/themes/projector.css" id="theme">
    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match( /print-pdf/gi ) ? '/ML_SA-Slides/lib/reveal.js/css/print/pdf.css' : '/ML_SA-Slides/lib/reveal.js/css/print/paper.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
    <!-- CUSTOM -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
    <base target="_blank">

    <style>
        .mj-left-align-block .MathJax_Display{
            padding: .5em 0 .5em 1em;
            text-align: left !important;
        }
    </style>
</head>
<body>
    <div class="reveal default center" data-transition-speed="default" data-background-transition="default">
    <div class="top_links">
        <a class="home_link" href="/ML_SA-Slides#Naive_Bayes_Classifiers" target="_top"></a>
        <span class="help_link"><i class="fa-solid fa-circle-question"></i></span>
        <div class="help_text">
            <div class="note">Keyboard shortcuts:</div>
            <div><span>N/Спейс</span><span>Next Slide</span></div>
            <div><span>P</span><span>Previous Slide</span></div>
            <div><span>O</span><span>Slides Overview</span></div>
            <div><span>ctrl+left click</span><span>Zoom Element</span></div>
            <div class="print-howto"><br>If you want print version => add '<code>?print-pdf</code>' <br> at the end of slides URL (remove '#' fragment) and then print. <br>
            Like: https://wwwcourses.github.io/...CourseIntro.html?print-pdf </div>
        </div>
    </div>
    <div class="footer theme_switch">
        <a href="#" onclick="document.getElementById('theme').setAttribute('href','/ML_SA-Slides/outfit/css/themes/dark.css'); return false;">Dark</a>
        <a href="#" onclick="document.getElementById('theme').setAttribute('href','/ML_SA-Slides/outfit/css/themes/light.css'); return false;">Light</a>
        <a href="#" onclick="document.getElementById('theme').setAttribute('href','/ML_SA-Slides/outfit/css/themes/projector.css'); return false;">Projector</a>
    </div>
    <div class="slides">
<!--
########################################################
##################### SLIDES START #####################
########################################################
-->
<section data-min-total="__X__" class="presentation-title"><h1>Naive Bayes Classifiers</h1></section>
<section data-transition="zoom">
    <section class="copyright" data-transition="zoom">
        <div>
            <p style="text-align: center;">Created for</p>
        </div>
        <div class="company">
            <a href="https://softwareacademy.bg/">
            <img style="height:80vh" src="/ML_SA-Slides/outfit/images/logos/software-web@4x.png" alt="software-web@4x.png">
            </a>
        </div>
        <div class="author">
            <span class="note"><a href="https://www.linkedin.com/in/ivapopova/">Iva E. Popova</a>,  2024,</span>
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png"></a>
            <!-- <i class="fa fa-linkedin"></i> -->
        </div>
    </section>
</section>


<section data-min="__Y__" class="main-section-title"><h1>Naive Bayes Classifier</h1></section>
<section class="sub-sections"><h2>Naive Bayes Classifier</h2>
    <section><h3>Bayes Theorem for Classification</h3>
        <dl class="fa">
            <dt>For each class $y_j$, calculate the probability of that class, given a feature vector $ {{x_1},...,{x_n}}$. I.e ${\rm{P}}\left( {y_j|{x_1},...,{x_n}} \right) = ?$</dt>
            <dt>Choose the class with highest probability.</dt>
            <dt>A Bayes Theorem can be applied to calculate that probability:</dt>
        </dl>
        <p>$${\rm{P}}\left( {y|{x_1},...,{x_n}} \right) = \frac{{{\rm{P}}\left( {{x_1},...,{x_n}|y} \right)} {\rm{P}}\left( y \right)}{{{\rm{P}}\left( {{x_1},...,{x_n}} \right)}} $$</p>
    </section>
    <section><h3>Why <span class="note">Naive</span>?</h3>
        <dl class="fa">
            <dt>It use the <i>naive independence assumption</i> - the probability of each feature belonging to a given class is independent of all other features.</dt>
            <!-- <dd>$P(xi|y,x1,...,xi−1,xi+1,...xn)=P(xi|y)$</dd> -->
            <dt>Using this naive independence assumption we re-express the Bayes' theorem to consider the probability of features independently: <br>
                $$ {\rm{P}}\left( {y|{x_1},...,{x_n}} \right) = \frac{{\prod\nolimits_{i = 1}^n {{\rm{P}}\left( {{x_i}|y} \right) {\rm{P}}\left( y \right)} }} {{{\rm{P}}\left( {{x_1},...,{x_n}} \right)}} $$
            </dt>
        </dl>
    </section>
    <section>
        <dl class="fa">
            <dt>The denominator ${{\rm{P}}\left( {{x_1},...,{x_n}} \right)}$ will be constant for all the classes, so we can ignore it in the calculations.</dt>
            <dt>Finally, the prediction output will be evaluated as: <br>
                $$ \hat y = \arg \mathop {\max }\limits_y \prod\nolimits_{i = 1}^n {{\rm{P}}\left( {{x_i}|y} \right) {\rm{P}}\left( y \right)} $$</dt>
        </dl>
    </section>
    <!-- <section><h3>Reference</h3>
        <dl class="fa">
            <dt><a href="https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/">An Intuitive (and Short) Explanation of Bayes’ Theorem</a></dt>
        </dl>
    </section> -->

    <section><h3>Reference</h3>
        <iframe width="535" src="https://www.youtube.com/embed/-RiNctT0lS8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </section>
    <section><h3></h3>
        <p><a href="https://www.youtube.com/watch?v=r1in0YNetG8">Naive Bayes 3: Gaussian example</a by Victor Lavrenko></p>
        <iframe width="806" height="504" src="https://www.youtube.com/embed/r1in0YNetG8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </section>
</section>

<section data-min="__Y__" class="main-section-title"><h1>Types of Naive Bayes Classifiers</h1></section>
<section class="sub-sections"><h2>Overview</h2>
    <section>
        <dl class="fa">
            <p>Another assumption made is about the probability distribution of the input features. Depending of that, there are several types of Naive Bayes Classifier</p>
            <dt>Bernoulli Naive Bayes Classifier</dt>
            <dd>The features are discrete Boolean data (1 or 0) and <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli distribution</a> is used</dd>
            <dt>Multinomial Naive Bayes Classifier</dt>
            <dd>Features are discrete (usually representing a count), and <a href="https://en.wikipedia.org/wiki/Multinomial_distribution">Multinomial distribution</a> is used</dd>
            <dt>Gaussian Naive Bayes Classifier</dt>
            <dd>Features are continuous and the <a href="https://en.wikipedia.org/wiki/Normal_distribution">normal ( Gaussian) distribution</a> is used</dd>
        </dl>
    </section>
</section>

<section data-min="__Y__" class="main-section-title"><h1>Bernoulli naive Bayes.</h1></section>
<section class="sub-sections"><h2>Bernoulli naive Bayes.</h2>
    <section><h3>Overview</h3>
        <dl class="fa">
            <dt>Bernoulli naive Bayes Classifier is applicable for binary features.</dt>
            <dt>I.e. when the features probability distribution is a <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli distribution</a></dt>
            <dt>It finds application in text classification, where the input vectors represent the presence (1) or absence (0) of a word from the lexicon in a document.</dt>
        </dl>
    </section>
</section>

<section data-min="__Y__" class="main-section-title"><h1>Gaussian Naive Bayes.</h1></section>
<section class="sub-sections"><h2>Gaussian Naive Bayes.</h2>
    <section>
        <dl class="fa">
            <dt>Description and examples are given in the notebook: <a href="examples/slides/NaiveBayes.html">NaiveBayes.html</a></dt>
        </dl>
    </section>
</section>

<section data-min="__Y__" class="main-section-title"><h1>Multinomial naive Bayes.</h1></section>
<section class="sub-sections"><h2>Multinomial naive Bayes.</h2>
    <section>
        <dl class="fa">
            <dt>Description and examples are given in the notebook: <a href="examples/slides/MultinomialNaiveBayes.html">MultinomialNaiveBayes.html</a></dt>
        </dl>
    </section>
</section>

<section data-min="__Y__" class="main-section-title"><h1>Pros and cons of Naive Bayes classifiers.</h1></section>
<section class="sub-sections"><h2>Pros and cons of Naive Bayes classifiers.</h2>
    <section><h3>Pros</h3>
        <dl class="fa">
            <dt>Extremely fast for both training and prediction</dt>
            <dt>Provide straightforward probabilistic prediction</dt>
            <dt>Easily interpretable</dt>
            <dt>Have very few (if any) tunable parameters</dt>
        </dl>
    </section>
    <section><h3>When to use?</h3>
        <p>Naive Bayes classifiers tend to perform especially well in one of the following situations:</p>
        <dl class="fa">
            <dt>When the naive assumptions actually match the data (very rare in practice)</dt>
            <dt>For very well-separated categories, when model complexity is less important</dt>
            <dt>For very high-dimensional data, when model complexity is less important</dt>
        </dl>
    </section>
</section>


<section id="hw" data-min="4"><h1>Exercises</h1></section>
<section class="sub-sections"><h2>Task1: Adult/Child classification
</h2>
    <section><h3>The Task</h3>
        <dl class="fa">
            <dt>The task is given in next JupyterNotebook: <a href="https://github.com/geekcourses/JupyterNotebooksExamples/blob/master/Notebooks/NaiveBayes/naive_bayes_children_and_adults_sklearn_TASK.ipynb">naive_bayes_children_and_adults_sklearn_TASK.ipynb</a></dt>
        </dl>
    </section>
</section>

<section><h3>Submission</h3>
    <dl class="fa">
        <dt>PLease, prefix your filenames/archive with your name initials, before sending.</dt>
        <dd>For instance: <b>iep_task1.py</b> or <b>iep_tasks.rar</b></dd>
        <dt>Send files to <a href="mailto:netIT.WWW.Courses@gmail.com?Subject=_Naive_Bayes_Classifiers_">netIT.WWW.Courses@gmail.com</a></dt>
    </dl>
</section>

<section class="disclaimer end-slide"></section>
<!--
########################################################
##################### SLIDES END   #####################
########################################################
-->
        </div>
    </div>
    <!-- Custom processing -->
    <script src="/ML_SA-Slides/outfit/js/slides.js"></script>
    <!-- external scripts -->
    <script src="/ML_SA-Slides/lib/reveal.js/lib/js/head.min.js"></script>
    <script src="/ML_SA-Slides/lib/reveal.js/js/reveal.js"></script>

    <!-- init reveal -->
    <script>
        // Full list of configuration options available at:
        // https://github.com/hakimel/reveal.js#configuration
        var highlightjsTabSize = '  ';
        Reveal.initialize({
            controls: true,
            progress: true,
            slideNumber: 'c/t',
            keyboard: true,
            history: true,

            // display control
            // center: true,
            // width: '100%',
            // height: '100%',
            // // // Factor of the display size that should remain empty around the content
            // margin: 0.1,

            // The "normal" size of the presentation, aspect ratio will be preserved
            // when the presentation is scaled to fit different resolutions. Can be
            // specified using percentage units.
            width: 1920,
            height: 1280,

            // Factor of the display size that should remain empty around the content
            margin: 0.1,

            // Bounds for smallest/largest possible scale to apply to content
            minScale: 0,
            maxScale: 2,

            // slide transition
            transition: 'concave', // none/fade/slide/convex/concave/zoom
            // shift+maous click to zoom in/out element
            zoomKey: 'ctrl',
            // theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
            // transition: Reveal.getQueryHash().transition || 'default'
            // Optional reveal.js plugins
            dependencies: [
                { src: '/ML_SA-Slides/lib/reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
                { src: '/ML_SA-Slides/lib/reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                { src: '/ML_SA-Slides/lib/reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                { src: '/ML_SA-Slides/lib/reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.configure({tabReplace: highlightjsTabSize}); hljs.initHighlightingOnLoad(); } },
                { src: '/ML_SA-Slides/lib/reveal.js/plugin/zoom-js/zoom.js', async: true },
                { src: '/ML_SA-Slides/lib/reveal.js/plugin/notes/notes.js', async: true }
            ]
        });
    </script>
    <!-- linkedin badge -->
    <!--<script type="text/javascript" src="https://platform.linkedin.com/badges/js/profile.js" async defer></script>-->

    <!-- MathJax -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript" async src="/ML_SA-Slides/lib/MathJax/MathJax.js?config=TeX-AMS_HTML-full"></script>
</body>
</html>
